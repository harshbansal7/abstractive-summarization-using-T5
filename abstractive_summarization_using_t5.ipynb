{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshbansal7/abstractive-summarization-using-T5/blob/master/abstractive_summarization_using_t5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jb4rNLO6CPO6",
        "outputId": "05d091c2-d84d-419b-aa23-251ea6f73f0e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the data into a DataFrame\n",
        "df = pd.read_csv(\"/content/abstractive-summarization-using-T5/datasets/train.csv\")\n",
        "df_val = pd.read_csv(\"/content/abstractive-summarization-using-T5/datasets/val.csv\")\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-01-21T12:38:23.434808Z",
          "iopub.execute_input": "2023-01-21T12:38:23.435260Z",
          "iopub.status.idle": "2023-01-21T12:38:24.718527Z",
          "shell.execute_reply.started": "2023-01-21T12:38:23.435177Z",
          "shell.execute_reply": "2023-01-21T12:38:24.717527Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OQnjsdJ7beC",
        "outputId": "d206236f-2f96-4398-d948-3781fa5c887e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(columns='FileName')\n",
        "df = df.rename(columns={\"Abstract\":\"source_text\", \"RHS\":\"target_text\"})\n",
        "df = df[['source_text', 'target_text']]\n",
        "\n",
        "df['source_text'] = \"summarize: \" + df['source_text']\n",
        "df\n",
        "\n",
        "df_val = df_val.drop(columns='FileName')\n",
        "df_val = df_val.rename(columns={\"Abstract\":\"source_text\", \"RHS\":\"target_text\"})\n",
        "df_val = df_val[['source_text', 'target_text']]\n",
        "\n",
        "df_val['source_text'] = \"summarize: \" + df_val['source_text']\n",
        "df_val"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-21T12:38:25.342466Z",
          "iopub.execute_input": "2023-01-21T12:38:25.342901Z",
          "iopub.status.idle": "2023-01-21T12:38:25.375703Z",
          "shell.execute_reply.started": "2023-01-21T12:38:25.342864Z",
          "shell.execute_reply": "2023-01-21T12:38:25.374698Z"
        },
        "trusted": true,
        "id": "P3nxTYS07beM",
        "outputId": "1c3630ad-1c87-49b5-ca17-73a169b8ebf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          source_text  \\\n",
              "0   summarize:  Human face can be seen as a soft t...   \n",
              "1   summarize:  In this paper we use a numerical p...   \n",
              "2   summarize:  Modularisation product platforms p...   \n",
              "3   summarize:  In order to investigate the micros...   \n",
              "4   summarize:  An efficient approach is proposed ...   \n",
              "..                                                ...   \n",
              "95  summarize:  This paper proposes a strategy for...   \n",
              "96  summarize:  A family of spatial beam finite el...   \n",
              "97  summarize:  A new adaptive multiscale method i...   \n",
              "98  summarize:  A nonlocal extension of the damage...   \n",
              "99  summarize:  This paper describes the developme...   \n",
              "\n",
              "                                          target_text  \n",
              "0   We model the deformation of the human face due...  \n",
              "1   Bifurcation and postbifurcation of inflated hy...  \n",
              "2   Existing methods in modular product family dev...  \n",
              "3   A DRX model of FGH96 of IFW process is establi...  \n",
              "4   Propose a pragmatic approach for simulating co...  \n",
              "..                                                ...  \n",
              "95  Efficient strategy for GPU computing of FGFEA ...  \n",
              "96  We analyse fixed pole approach in geometricall...  \n",
              "97  A new adaptive multiscale method AMM is develo...  \n",
              "98  A new nonlocal damage plasticity model has bee...  \n",
              "99  A finite element model of bolt is proposed to ...  \n",
              "\n",
              "[100 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1390bed4-2039-4d76-abf2-c43bb06a85ed\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source_text</th>\n",
              "      <th>target_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>summarize:  Human face can be seen as a soft t...</td>\n",
              "      <td>We model the deformation of the human face due...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>summarize:  In this paper we use a numerical p...</td>\n",
              "      <td>Bifurcation and postbifurcation of inflated hy...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>summarize:  Modularisation product platforms p...</td>\n",
              "      <td>Existing methods in modular product family dev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>summarize:  In order to investigate the micros...</td>\n",
              "      <td>A DRX model of FGH96 of IFW process is establi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>summarize:  An efficient approach is proposed ...</td>\n",
              "      <td>Propose a pragmatic approach for simulating co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>summarize:  This paper proposes a strategy for...</td>\n",
              "      <td>Efficient strategy for GPU computing of FGFEA ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>summarize:  A family of spatial beam finite el...</td>\n",
              "      <td>We analyse fixed pole approach in geometricall...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>summarize:  A new adaptive multiscale method i...</td>\n",
              "      <td>A new adaptive multiscale method AMM is develo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>summarize:  A nonlocal extension of the damage...</td>\n",
              "      <td>A new nonlocal damage plasticity model has bee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>summarize:  This paper describes the developme...</td>\n",
              "      <td>A finite element model of bolt is proposed to ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1390bed4-2039-4d76-abf2-c43bb06a85ed')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1390bed4-2039-4d76-abf2-c43bb06a85ed button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1390bed4-2039-4d76-abf2-c43bb06a85ed');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install --upgrade simplet5"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-21T12:38:25.377086Z",
          "iopub.execute_input": "2023-01-21T12:38:25.378048Z",
          "iopub.status.idle": "2023-01-21T12:38:59.455568Z",
          "shell.execute_reply.started": "2023-01-21T12:38:25.378012Z",
          "shell.execute_reply": "2023-01-21T12:38:59.454440Z"
        },
        "trusted": true,
        "id": "7EgYrmMJ7beN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from simplet5 import SimpleT5\n",
        "model = SimpleT5()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-21T12:38:59.457365Z",
          "iopub.execute_input": "2023-01-21T12:38:59.458095Z",
          "iopub.status.idle": "2023-01-21T12:39:14.528255Z",
          "shell.execute_reply.started": "2023-01-21T12:38:59.458055Z",
          "shell.execute_reply": "2023-01-21T12:39:14.527161Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDO1RkYk7beO",
        "outputId": "1fc9d3eb-9dd8-4c54-b87f-e1dc7c741d20"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.seed:Global seed set to 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load (supports t5, mt5, byT5 models)\n",
        "# model.from_pretrained(\"t5\",\"t5-base\")\n",
        "\n",
        "# model.train(train_df=df, # pandas dataframe with 2 columns: source_text & target_text\n",
        "#             eval_df=df_val, # pandas dataframe with 2 columns: source_text & target_text\n",
        "#             source_max_token_len = 512, \n",
        "#             target_max_token_len = 100,\n",
        "#             batch_size = 8,\n",
        "#             max_epochs = 10,\n",
        "#             use_gpu = True,\n",
        "#             outputdir = \"/content\",\n",
        "#             early_stopping_patience_epochs = 0,\n",
        "#             precision = 32\n",
        "# )"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-21T12:39:14.529713Z",
          "iopub.execute_input": "2023-01-21T12:39:14.530454Z",
          "iopub.status.idle": "2023-01-21T12:53:18.230822Z",
          "shell.execute_reply.started": "2023-01-21T12:39:14.530415Z",
          "shell.execute_reply": "2023-01-21T12:53:18.229763Z"
        },
        "trusted": true,
        "id": "VEaxnGs57beP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import shutil\n",
        "# shutil.make_archive('model-archive', 'zip', '/content/simplet5-epoch-9-train-loss-1.3233-val-loss-2.5556')"
      ],
      "metadata": {
        "id": "1il3xBlhhMTU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_model(\"t5\",\"/content/abstractive-summarization-using-T5/simplet5-epoch-9-train-loss-1.3675-val-loss-2.6217\", use_gpu=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-21T12:53:53.360566Z",
          "iopub.execute_input": "2023-01-21T12:53:53.360921Z",
          "iopub.status.idle": "2023-01-21T12:53:54.526893Z",
          "shell.execute_reply.started": "2023-01-21T12:53:53.360891Z",
          "shell.execute_reply": "2023-01-21T12:53:54.525559Z"
        },
        "trusted": true,
        "id": "T8KwnK0i7beQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install pytextrank\n",
        "!python -m spacy download en_core_web_sm\n",
        "!pip install --upgrade scipy networkx"
      ],
      "metadata": {
        "_kg_hide-output": false,
        "execution": {
          "iopub.status.idle": "2023-01-21T12:54:32.642652Z",
          "shell.execute_reply.started": "2023-01-21T12:53:56.168517Z",
          "shell.execute_reply": "2023-01-21T12:54:32.641478Z"
        },
        "trusted": true,
        "id": "E-azzzMe7beQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import pytextrank\n",
        "\n",
        "def extract_important_sentences(text, limit_phrases=15, limit_sentences=5):\n",
        "    en_nlp = spacy.load(\"en_core_web_sm\")\n",
        "    en_nlp.add_pipe(\"textrank\", last=True)\n",
        "    doc = en_nlp(text)\n",
        "    tr = doc._.textrank\n",
        "    summary = \"\"\n",
        "    for sent in tr.summary(limit_phrases=limit_phrases, limit_sentences=limit_sentences):\n",
        "        summary += sent.text + \" \"\n",
        "    return summary"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-21T13:05:02.254650Z",
          "iopub.execute_input": "2023-01-21T13:05:02.255053Z",
          "iopub.status.idle": "2023-01-21T13:05:02.262452Z",
          "shell.execute_reply.started": "2023-01-21T13:05:02.255019Z",
          "shell.execute_reply": "2023-01-21T13:05:02.261113Z"
        },
        "trusted": true,
        "id": "FpeCXN6d7beR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_summaries(text):\n",
        "\n",
        "    print(\"ACTUAL ABSTRACT - \" + text)\n",
        "    print(\"\\nLength of Abstract = \" + str(len(text.split())))\n",
        "    sumtext = \"summarize: \" + text\n",
        "    actual_text_prediction = model.predict(sumtext)[0]\n",
        "    print(\"\\nDIRECT SUMMARIZATION USING T5 - \" + actual_text_prediction)\n",
        "    print(\"\\nLength of Summary = \" + str(len(actual_text_prediction.split())))\n",
        "\n",
        "    newtext = extract_important_sentences(text, 20, 5)\n",
        "    newtext = \"summarize: \" + newtext\n",
        "    extractive_text_prediction = model.predict(newtext)[0]\n",
        "    print(\"\\nSUMMARIZATION AFTER EXTRACTIVE USING T5 - \" + extractive_text_prediction)\n",
        "    print(\"\\nLength of Summary = \" + str(len(extractive_text_prediction.split())))"
      ],
      "metadata": {
        "id": "wcIQOHTVDo-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"Since their early discovery, thin films have quickly found industrial uses, including in ornamental and optical applications. The range of applications for thin film technology has expanded to the point where nearly every industrial sector now uses it to impart specific physical and chemical properties to the surface of bulk materials. This expansion has been aided by the development of vacuum technology and electric power facilities. Recently, the most technologically sophisticated applications, such microelectronics and biomedicine, have been made possible by the ability to adjust the film properties by the change of the microstructure via the deposition parameters used in a particular deposition procedure. Despite such remarkable advancements, the relationship between all phases of the manufacture of thin films, specifically deposition parameters-morphology and characteristics, is not entirely precise. The development of complex models for an accurate prediction of film properties has been hampered, among other things, by the lack of characterization techniques suited for probing films with thickness less than a single atomic layer and a lack of knowledge of the physics. Additionally, there are still certain challenges with the mass production of advanced structures, such as quantum wells and wires, as well as a relatively high cost for their deposition. Thin film technology will be more competitive for cutting-edge technological applications once these obstacles are removed.\"\"\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-21T13:26:54.838972Z",
          "iopub.execute_input": "2023-01-21T13:26:54.839364Z",
          "iopub.status.idle": "2023-01-21T13:26:54.845014Z",
          "shell.execute_reply.started": "2023-01-21T13:26:54.839332Z",
          "shell.execute_reply": "2023-01-21T13:26:54.843921Z"
        },
        "trusted": true,
        "id": "UeSY5X5f7beR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_summaries(text)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-21T13:26:56.318085Z",
          "iopub.execute_input": "2023-01-21T13:26:56.318833Z",
          "iopub.status.idle": "2023-01-21T13:26:56.991525Z",
          "shell.execute_reply.started": "2023-01-21T13:26:56.318787Z",
          "shell.execute_reply": "2023-01-21T13:26:56.989803Z"
        },
        "trusted": true,
        "id": "w_Gjt1iq7beR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an empty dataframe\n",
        "pred_df = pd.DataFrame(columns=[\"target_text\", \"predicted_text\", \"predicted_after_extractive\"])\n",
        "\n",
        "df_val = pd.read_csv(\"/content/abstractive-summarization-using-T5/datasets/val.csv\")\n",
        "df_val = df_val.drop(columns='FileName')\n",
        "df_val = df_val.rename(columns={\"Abstract\":\"source_text\", \"RHS\":\"target_text\"})\n",
        "df_val = df_val[['source_text', 'target_text']]\n",
        "\n",
        "# Iterate over the validation dataset\n",
        "for i, row in df_val.iterrows():\n",
        "    # Make a prediction for the current row\n",
        "    pred_text = model.predict(\"summarize: \" + row[\"source_text\"])\n",
        "    newtext = extract_important_sentences(row[\"source_text\"], 25, 6)\n",
        "    newtext = \"summarize: \" + newtext\n",
        "    pred_text2 = model.predict(newtext)\n",
        "    # Add the prediction and the target text to the new dataframe\n",
        "    pred_df.loc[i] = [row[\"target_text\"], pred_text[0], pred_text2[0]]\n",
        "    \n",
        "pred_df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-21T13:38:56.150598Z",
          "iopub.execute_input": "2023-01-21T13:38:56.150948Z",
          "iopub.status.idle": "2023-01-21T13:40:28.511595Z",
          "shell.execute_reply.started": "2023-01-21T13:38:56.150912Z",
          "shell.execute_reply": "2023-01-21T13:40:28.510580Z"
        },
        "trusted": true,
        "id": "fX-M0O0C7beU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install py-rouge"
      ],
      "metadata": {
        "id": "gN5er3jxEWRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import rouge\n",
        "\n",
        "def prepare_results(p, r, f):\n",
        "    return '\\t{}:\\t{}: {:5.2f}\\t{}: {:5.2f}\\t{}: {:5.2f}'.format(metric, 'P', 100.0 * p, 'R', 100.0 * r, 'F1', 100.0 * f)\n",
        "\n",
        "print(\"Results on Predictions Directly using T5\\n\")\n",
        "for aggregator in ['Avg', 'Best']:\n",
        "    print('Evaluation with {}'.format(aggregator))\n",
        "    apply_avg = aggregator == 'Avg'\n",
        "    apply_best = aggregator == 'Best'\n",
        "\n",
        "    evaluator = rouge.Rouge(metrics=['rouge-n', 'rouge-l', 'rouge-w'],\n",
        "                           max_n=2,\n",
        "                           limit_length=True,\n",
        "                           length_limit=100,\n",
        "                           length_limit_type='words',\n",
        "                           apply_avg=apply_avg,\n",
        "                           apply_best=apply_best,\n",
        "                           alpha=0.5, # Default F1_score\n",
        "                           weight_factor=1.2,\n",
        "                           stemming=True)\n",
        "\n",
        "\n",
        "    all_hypothesis = pred_df['predicted_text']\n",
        "    all_references = pred_df['target_text']\n",
        "\n",
        "    scores = evaluator.get_scores(all_hypothesis, all_references)\n",
        "\n",
        "    for metric, results in sorted(scores.items(), key=lambda x: x[0]):\n",
        "        if not apply_avg and not apply_best: # value is a type of list as we evaluate each summary vs each reference\n",
        "            for hypothesis_id, results_per_ref in enumerate(results):\n",
        "                nb_references = len(results_per_ref['p'])\n",
        "                for reference_id in range(nb_references):\n",
        "                    print('\\tHypothesis #{} & Reference #{}: '.format(hypothesis_id, reference_id))\n",
        "                    print('\\t' + prepare_results(results_per_ref['p'][reference_id], results_per_ref['r'][reference_id], results_per_ref['f'][reference_id]))\n",
        "            print()\n",
        "        else:\n",
        "            print(prepare_results(results['p'], results['r'], results['f']))\n",
        "    print()\n",
        "\n",
        "print(\"Results on Predictions from Extractive + T5\\n\")\n",
        "for aggregator in ['Avg', 'Best']:\n",
        "    print('Evaluation with {}'.format(aggregator))\n",
        "    apply_avg = aggregator == 'Avg'\n",
        "    apply_best = aggregator == 'Best'\n",
        "\n",
        "    evaluator = rouge.Rouge(metrics=['rouge-n', 'rouge-l', 'rouge-w'],\n",
        "                           max_n=2,\n",
        "                           limit_length=True,\n",
        "                           length_limit=100,\n",
        "                           length_limit_type='words',\n",
        "                           apply_avg=apply_avg,\n",
        "                           apply_best=apply_best,\n",
        "                           alpha=0.5, # Default F1_score\n",
        "                           weight_factor=1.2,\n",
        "                           stemming=True)\n",
        "\n",
        "\n",
        "    all_hypothesis = pred_df['predicted_after_extractive']\n",
        "    all_references = pred_df['target_text']\n",
        "\n",
        "    scores = evaluator.get_scores(all_hypothesis, all_references)\n",
        "\n",
        "    for metric, results in sorted(scores.items(), key=lambda x: x[0]):\n",
        "        if not apply_avg and not apply_best: # value is a type of list as we evaluate each summary vs each reference\n",
        "            for hypothesis_id, results_per_ref in enumerate(results):\n",
        "                nb_references = len(results_per_ref['p'])\n",
        "                for reference_id in range(nb_references):\n",
        "                    print('\\tHypothesis #{} & Reference #{}: '.format(hypothesis_id, reference_id))\n",
        "                    print('\\t' + prepare_results(results_per_ref['p'][reference_id], results_per_ref['r'][reference_id], results_per_ref['f'][reference_id]))\n",
        "            print()\n",
        "        else:\n",
        "            print(prepare_results(results['p'], results['r'], results['f']))\n",
        "    print()"
      ],
      "metadata": {
        "id": "FZEHqeADEaPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Few Examples**"
      ],
      "metadata": {
        "id": "r-ortkC3xVik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "create_summaries(\"\"\"The study objective is to contemplate the effectiveness of COVID-19 on the air pollution of Indian ter\u0002ritory from January 2020 to April 2020. We have executed data from European Space Agency (ESA) and CPCB online portal for air quality data dissemination. The Sentinel e 5 P satellite images elucidate that the Air quality of Indian territory has been improved significantly during COVID-19. Mumbai and Delhi are one of the most populated cities. These two cities have observed a substantial decrease in Nitrogen Dioxide (40e50%) compared to the same period last year. It suggests that the emergence of COVID-19 has been proved to a necessary evil as being advantageous for mitigating air pollution on Indian territory during the lock-down. The study found a significant decline in Nitrogen Dioxide in reputed states of India, i.e., Delhi and Mumbai. Moreover, a faded track of Nitrogen Dioxide can be seen at the Maritime route in the Indian Ocean. An upsurge in the environmental quality of India will also be beneficial for its neighbor countries, i.e., China, Pakistan, Iran, and Afghanistan.\"\"\")"
      ],
      "metadata": {
        "id": "abNM4-GDFdVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_summaries(\"\"\"The aim of the study is to introduce some approach which might help in improving daily temperature of data. Weather is a natural a phenomenon for which forecasting is a great challenge today. Weather parameters such as Rainfall, Relative Humidity , Wind Speed, Air Temperature are highly non-linear and complex phenomena, which include mathematical simulation and modeling for its correct forecasting. Weather Forecasting is use to simplify the purpose of knowledge and tools that are used for the state of atmosphere at a given place. The prediction is becoming more complicated due to changing weather condition. There are different software and types are available for Time Series forecasting. Our aim is to analyze the parameters and do the comparison of some strategies in predicting these temperatures. Here we tend to analyze the data of given parameters and notice the prediction for few period using the strategy of Autoregressive Integrated Moving Average (ARIMA) and Exponential Smoothing (ETS).The data from meteorological centers are taken for comparison of methods using packages such as ggplot2, forecast, time Date in R and automatic prediction strategies are available within the package applied for modeling with ARIMA and ETS methods. On basis of accuracy we tend to attempt the simplest Methodology. Our model will compare on basis of MAE, MASE, MAPE AND RMSE. The identification of model will chromatic inspection of both the ACF and PACF to hypothesize many possible models will estimated by selection criteria AIC, AICc and BIC.\"\"\")"
      ],
      "metadata": {
        "id": "34u0j7evVzsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_summaries(\"\"\"This paper explores the concept of economies and diseconomies of scale in the production process. Economies of scale refer to cost advantages that a firm experience as it increases its level of output, while diseconomies of scale refer to the increased costs that a firm experience as it increases its level of output. The paper provides a comprehensive examination of the different types of economies and diseconomies of scale, including internal and external economies and diseconomies of scale. The paper also discusses the various factors that can affect economies and diseconomies of scale and provides insights on how firms can effectively navigate these challenges. The paper concludes by highlighting the importance of considering economies and diseconomies of scale in the production process and the impact it can have on the overall efficiency and profitability of a firm.\"\"\")"
      ],
      "metadata": {
        "id": "uEAmie4fvogf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summarizing Examples"
      ],
      "metadata": {
        "id": "Anp9YlKHyCeS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "create_summaries(\"\"\"Let's use two hypothetical retail businesses as an example and compare them. One of them is a major company by the name of Malwart, while the other is a tiny neighbourhood shop by the name of Bob's Sporting Goods. Bob handles all of his distribution and inventory management manually and alone. Malwart maintains its distribution in the meanwhile using sophisticated software created only for them. It should come as no surprise that Malwart manages his inventory and distribution considerably more effectively and productively than Bob does. However, because his business is too small and he cannot afford to spend so much money, Bob is unable to invest in similar software.\"\"\")"
      ],
      "metadata": {
        "id": "86KGHub4wqJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summarizing generic text paragraphs"
      ],
      "metadata": {
        "id": "Ke3E6LfcyD2B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "create_summaries(\"\"\"Holi is the festival of colors celebrated with our loved ones. It is one of the biggest festivals in our country which comes every year during March. Children, adults and even the elder citizens take part in the fun and preparations of Holi for three days starting from a full moon day. People from all religions play Holi by exchanging sweets, gujiya, thandai and splashing colors on each other. Water guns and water balloons are also used by children during the Holidays.\"\"\")"
      ],
      "metadata": {
        "id": "0Ob8T00FxFxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_df"
      ],
      "metadata": {
        "id": "lEwDUYcbJT0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "smoothie = SmoothingFunction().method4\n",
        "def calculate_bleu(row):\n",
        "    reference = row['target_text']\n",
        "    hypothesis = row['predicted_text']\n",
        "    score = sentence_bleu([reference.split()], hypothesis.split(), smoothing_function=smoothie)\n",
        "    return score\n",
        "\n",
        "def calculate_bleu_extractive(row):\n",
        "    reference = row['target_text']\n",
        "    hypothesis = row['predicted_after_extractive']\n",
        "    score = sentence_bleu([reference.split()], hypothesis.split(), smoothing_function=smoothie)\n",
        "    return score\n",
        "\n",
        "pred_df['bleu_score'] = pred_df.apply(calculate_bleu, axis=1)\n",
        "pred_df['bleu_score_extractive'] = pred_df.apply(calculate_bleu_extractive, axis=1)\n"
      ],
      "metadata": {
        "id": "PJL_E8ToInWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pred_df['bleu_score'].mean())\n",
        "print(pred_df['bleu_score_extractive'].mean())"
      ],
      "metadata": {
        "id": "HFnFXd_0LrrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install eaas"
      ],
      "metadata": {
        "id": "ys4hSplBSmd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from simplet5 import SimpleT5\n",
        "import spacy\n",
        "import pytextrank\n",
        "from eaas import Config, Client\n",
        "\n",
        "def use_gradio_summary(text):\n",
        "\n",
        "    sumtext = \"summarize: \" + text\n",
        "    actual_text_prediction = model.predict(sumtext)[0]\n",
        "\n",
        "    newtext = extract_important_sentences(text, 20, 6)\n",
        "    newtext = \"summarize: \" + newtext\n",
        "    extractive_text_prediction = model.predict(newtext)[0]\n",
        "    \n",
        "    return actual_text_prediction, extractive_text_prediction\n",
        "    \n",
        "\n",
        "def calculate_scores(src, text):\n",
        "    client = Client(Config())\n",
        "    metrics = [\"bert_score_f\"]\n",
        "\n",
        "    inputs = [{\n",
        "        \"references\":src,\n",
        "        \"hypothesis\":text\n",
        "    }]\n",
        "\n",
        "    score_dic = client.score(inputs, metrics=metrics)\n",
        "    \n",
        "    return str(float(score_dic['scores'][0]['corpus']) * 100)[:5]\n",
        "\n",
        "with gr.Blocks() as iface:\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1, min_width=600):\n",
        "            inputBox = gr.TextArea(label=\"Enter Abstract of any Research Paper\")\n",
        "            b1 = gr.Button(\"Perform Summarization\")\n",
        "    with gr.Row():\n",
        "        text1 = gr.TextArea(label=\"Direct T5 Summary\")\n",
        "        text2 = gr.TextArea(label=\"After Extractive T5 Summary\")\n",
        "    with gr.Row():\n",
        "      with gr.Column():\n",
        "        text1score = gr.Textbox(label=\"BERT Score Direct T5\")\n",
        "        bleft = gr.Button(\"Evaluate Direct T5\")\n",
        "      with gr.Column():\n",
        "        text2score = gr.Textbox(label=\"BERT Score After Extractive T5 Summary\")\n",
        "        bright = gr.Button(\"Evaluate Extractive + T5\")        \n",
        "\n",
        "    b1.click(use_gradio_summary, inputs=inputBox, outputs=[text1, text2])\n",
        "    bleft.click(calculate_scores, inputs=[inputBox, text1], outputs=text1score)\n",
        "    bright.click(calculate_scores, inputs=[inputBox, text2], outputs=text2score)\n",
        "    \n",
        "# Running the app\n",
        "iface.launch()"
      ],
      "metadata": {
        "id": "9AhyOThGNrqk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}